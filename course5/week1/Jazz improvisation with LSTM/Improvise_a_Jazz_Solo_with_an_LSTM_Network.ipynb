{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc3b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from music21 import *\n",
    "from grammar import *\n",
    "from qa import *\n",
    "from preprocess import * \n",
    "from music_utils import *\n",
    "from data_utils import *\n",
    "from outputs import *\n",
    "from test_utils import *\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio('./data/30s_trained_model.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, n_values, indices_values, chords = load_music_utils('data/original_metheny.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1908e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch music21.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4940aab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Deep-env37]",
   "language": "python",
   "name": "conda-env-Deep-env37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
