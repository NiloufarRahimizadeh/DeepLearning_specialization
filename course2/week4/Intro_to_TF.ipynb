{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894e14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from tensorflow.python.ops.resource_variable_ops import ResourceVariable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3e62da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705523b",
   "metadata": {},
   "source": [
    "### Basic Optimization with GradientTape\n",
    "\n",
    "The beauty of TensorFlow 2 is in its simplicity. Basically, all you need to do is implement forward propagation through a computational graph. TensorFlow will compute the derivatives for you, by moving backwards through the graph recorded with GradientTape. All that's left for you to do then is specify the cost function and optimizer you want to use!\n",
    "\n",
    "When writing a TensorFlow program, the main object to get used and transformed is the tf.Tensor. These tensors are the TensorFlow equivalent of Numpy arrays, i.e. multidimensional arrays of a given data type that also contain information about the computational graph.\n",
    "\n",
    "Below, you'll use tf.Variable to store the state of your variables. Variables can only be created once as its initial value defines the variable shape and type. Additionally, the dtype arg in tf.Variable can be set to allow data to be converted to that type. But if none is specified, either the datatype will be kept if the initial value is a Tensor, or convert_to_tensor will decide. It's generally best for you to specify directly, so nothing breaks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786fdc09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = h5py.File(\"dataset/train_signs.h5\")\n",
    "test_dataset = h5py.File(\"dataset/test_signs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b631996e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"train_set_x\": shape (1080, 64, 64, 3), type \"|u1\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"train_set_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8721fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.data.Dataset.from_tensor_slices(train_dataset[\"train_set_x\"])\n",
    "y_train = tf.data.Dataset.from_tensor_slices(train_dataset[\"train_set_y\"])\n",
    "\n",
    "x_test = tf.data.Dataset.from_tensor_slices(test_dataset[\"test_set_x\"])\n",
    "y_test = tf.data.Dataset.from_tensor_slices(test_dataset[\"test_set_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a05aa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42268204",
   "metadata": {},
   "source": [
    "Since TensorFlow Datasets are generators, you can't access directly the contents unless you iterate over them in a for loop, or by explicitly creating a Python iterator using iter and consuming its elements using next. Also, you can inspect the shape and dtype of each element using the element_spec attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c738bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(64, 64, 3), dtype=tf.uint8, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1465033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(64, 64, 3), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b13089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[227 220 214]\n",
      "  [227 221 215]\n",
      "  [227 222 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [230 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 215]\n",
      "  [228 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 222]\n",
      "  [231 229 221]]\n",
      "\n",
      " [[227 221 214]\n",
      "  [227 221 214]\n",
      "  [227 221 215]\n",
      "  ...\n",
      "  [232 230 224]\n",
      "  [231 229 223]\n",
      "  [230 229 221]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[119  81  51]\n",
      "  [124  85  55]\n",
      "  [127  87  58]\n",
      "  ...\n",
      "  [210 211 211]\n",
      "  [211 212 210]\n",
      "  [210 211 210]]\n",
      "\n",
      " [[119  79  51]\n",
      "  [124  84  55]\n",
      "  [126  85  56]\n",
      "  ...\n",
      "  [210 211 210]\n",
      "  [210 211 210]\n",
      "  [209 210 209]]\n",
      "\n",
      " [[119  81  51]\n",
      "  [123  83  55]\n",
      "  [122  82  54]\n",
      "  ...\n",
      "  [209 210 210]\n",
      "  [209 210 209]\n",
      "  [208 209 209]]], shape=(64, 64, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3306cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for element in x_train:\n",
    "#     print(element)\n",
    "    i = i + 1\n",
    "#     break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e998147",
   "metadata": {},
   "source": [
    "There's one more additional difference between TensorFlow datasets and Numpy arrays: If you need to transform one, you would invoke the map method to apply the function passed as an argument to each of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8156e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32) / 256.\n",
    "    image = tf.reshape(image, [-1, 1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641dbc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = x_train.map(normalize)\n",
    "new_test = y_train.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af0af14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(12288, 1), dtype=tf.float32, name=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e674e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.88671875]\n",
      " [0.859375  ]\n",
      " [0.8359375 ]\n",
      " ...\n",
      " [0.8125    ]\n",
      " [0.81640625]\n",
      " [0.81640625]], shape=(12288, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 00:44:59.468279: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31aa8ac",
   "metadata": {},
   "source": [
    "### Linear Function\n",
    "Note that the difference between tf.constant and tf.Variable is that you can modify the state of a tf.Variable but cannot change the state of a tf.constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66a531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    np.random.seed(1)\n",
    "    X = tf.constant(np.random.randn(3, 1))\n",
    "    W = tf.constant(np.random.randn(4, 3))\n",
    "    b = tf.constant(np.random.randn(4, 1))\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "271fd382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]], shape=(4, 1), dtype=float64)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "result = linear_function()\n",
    "print(result)\n",
    "\n",
    "assert type(result) == EagerTensor, \"Use the TensorFlow API\"\n",
    "assert np.allclose(result, [[-2.15657382], [ 2.95891446], [-1.08926781], [-0.84538042]]), \"Error\"\n",
    "print(\"\\033[92mAll test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba56b5a",
   "metadata": {},
   "source": [
    "### Computing the Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0284ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    z = tf.cast(z, tf.float32)\n",
    "    a = tf.keras.activations.sigmoid(z)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e779b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "dtype: <dtype: 'float32'>\n",
      "sigmoid(-1) = tf.Tensor(0.26894143, shape=(), dtype=float32)\n",
      "sigmoid(0) = tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "sigmoid(12) = tf.Tensor(0.9999939, shape=(), dtype=float32)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "result = sigmoid(-1)\n",
    "print (\"type: \" + str(type(result)))\n",
    "print (\"dtype: \" + str(result.dtype))\n",
    "print (\"sigmoid(-1) = \" + str(result))\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0.0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))\n",
    "\n",
    "def sigmoid_test(target):\n",
    "    result = target(0)\n",
    "    assert(type(result) == EagerTensor)\n",
    "    assert (result.dtype == tf.float32)\n",
    "    assert sigmoid(0) == 0.5, \"Error\"\n",
    "    assert sigmoid(-1) == 0.26894143, \"Error\"\n",
    "    assert sigmoid(12) == 0.9999939, \"Error\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19723a",
   "metadata": {},
   "source": [
    "### Using One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce4cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(label, depth=6):\n",
    "    \n",
    "    \"\"\" label --  (int) Categorical labels\n",
    "        depth --  (int) Number of different classes that label can take\n",
    "    \"\"\"\n",
    "    one_hot = tf.one_hot(label, depth, axis=0)\n",
    "    one_hot = tf.reshape(one_hot,[depth,1])\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e161f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_matrix(tf.constant(2), depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8e5882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = y_test.map(one_hot_matrix)\n",
    "new_y_train = y_train.map(one_hot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c067210e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=TensorSpec(shape=(6, 1), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd40d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(6, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b41b28",
   "metadata": {},
   "source": [
    "### Initialize the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ebbcf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=1)   \n",
    "    #(approx. 6 lines of code)\n",
    "    W1 = tf.Variable(initializer(shape=(25, 12288)))\n",
    "    b1 = tf.Variable(initializer(shape=(25, 1)))\n",
    "    W2 = tf.Variable(initializer(shape=(12, 25)))\n",
    "    b2 = tf.Variable(initializer(shape=(12, 1)))\n",
    "    W3 = tf.Variable(initializer(shape=(6,12)))\n",
    "    b3 = tf.Variable(initializer(shape=(6, 1)))\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e48312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape: (25, 12288)\n",
      "b1 shape: (25, 1)\n",
      "W2 shape: (12, 25)\n",
      "b2 shape: (12, 1)\n",
      "W3 shape: (6, 12)\n",
      "b3 shape: (6, 1)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters_test(target):\n",
    "    parameters = target()\n",
    "\n",
    "    values = {\"W1\": (25, 12288),\n",
    "              \"b1\": (25, 1),\n",
    "              \"W2\": (12, 25),\n",
    "              \"b2\": (12, 1),\n",
    "              \"W3\": (6, 12),\n",
    "              \"b3\": (6, 1)}\n",
    "\n",
    "    for key in parameters:\n",
    "        print(f\"{key} shape: {tuple(parameters[key].shape)}\")\n",
    "        assert type(parameters[key]) == ResourceVariable, \"All parameter must be created using tf.Variable\"\n",
    "        assert tuple(parameters[key].shape) == values[key], f\"{key}: wrong shape\"\n",
    "        assert np.abs(np.mean(parameters[key].numpy())) < 0.5,  f\"{key}: Use the GlorotNormal initializer\"\n",
    "        assert np.std(parameters[key].numpy()) > 0 and np.std(parameters[key].numpy()) < 1, f\"{key}: Use the GlorotNormal initializer\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "    \n",
    "initialize_parameters_test(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5ebc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bffbcf3",
   "metadata": {},
   "source": [
    "## Building Your First Neural Network in TensorFlow\n",
    "* Implement forward propagation\n",
    "* Retrieve the gradients and train the model\n",
    "\n",
    "One of TensorFlow's great strengths lies in the fact that you only need to implement the forward propagation function.\n",
    "\n",
    "Here, you'll use a TensorFlow decorator, @tf.function, which builds a computational graph to execute the function. @tf.function is polymorphic, which comes in very handy, as it can support arguments with different data types or shapes, and be used with other languages, such as Python. This means that you can use data dependent control flow statements.\n",
    "\n",
    "When you use @tf.function to implement forward propagation, the computational graph is activated, which keeps track of the operations. This is so you can calculate your gradients with backpropagation.\n",
    "\n",
    "### forward_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88482729",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    #(approx. 5 lines)                   # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)    # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.keras.activations.relu(Z1) # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)   # Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = tf.keras.activations.relu(Z2) # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)   # Z3 = np.dot(W3, A2) + b3\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc92d15b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Output does not match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[92mAll test passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mforward_propagation_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_propagation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mforward_propagation_test\u001b[0;34m(target, examples)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m forward_pass\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLast layer must use W3 and b3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(forward_pass \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use a ReLu layer at end of your network\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(forward_pass, \n\u001b[1;32m      8\u001b[0m                    [[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.13082162\u001b[39m],\n\u001b[1;32m      9\u001b[0m                    [ \u001b[38;5;241m0.21228778\u001b[39m],\n\u001b[1;32m     10\u001b[0m                    [ \u001b[38;5;241m0.7050022\u001b[39m ],\n\u001b[1;32m     11\u001b[0m                    [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.1224034\u001b[39m ],\n\u001b[1;32m     12\u001b[0m                    [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.20386729\u001b[39m],\n\u001b[1;32m     13\u001b[0m                    [ \u001b[38;5;241m0.9526217\u001b[39m ]]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(forward_pass)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Output does not match"
     ]
    }
   ],
   "source": [
    "def forward_propagation_test(target, examples):\n",
    "    for batch in examples:\n",
    "        forward_pass = target(batch, parameters)\n",
    "        assert type(forward_pass) == EagerTensor, \"Your output is not a tensor\"\n",
    "        assert forward_pass.shape == (6, 1), \"Last layer must use W3 and b3\"\n",
    "        assert np.any(forward_pass < 0), \"Don't use a ReLu layer at end of your network\"\n",
    "        assert np.allclose(forward_pass, \n",
    "                           [[-0.13082162],\n",
    "                           [ 0.21228778],\n",
    "                           [ 0.7050022 ],\n",
    "                           [-1.1224034 ],\n",
    "                           [-0.20386729],\n",
    "                           [ 0.9526217 ]]), \"Output does not match\"\n",
    "        print(forward_pass)\n",
    "        break\n",
    "    \n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "forward_propagation_test(forward_propagation, new_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a13519",
   "metadata": {},
   "source": [
    "## Compute the Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7eb85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_cost(logits, labels):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels, logits, from_logits=True))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "795be85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.8419182681095858, shape=(), dtype=float64)\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "def compute_cost_test(target):\n",
    "    labels = np.array([[0., 1.], [0., 0.], [1., 0.]])\n",
    "    logits = np.array([[0.6, 0.4], [0.4, 0.6], [0.4, 0.6]])\n",
    "    result = compute_cost(logits, labels)\n",
    "    print(result)\n",
    "    assert(type(result) == EagerTensor), \"Use the TensorFlow API\"\n",
    "    assert (np.abs(result - (0.7752516 +  0.9752516 + 0.7752516) / 3.0) < 1e-7), \"Test does not match. Did you get the mean of your cost functions?\"\n",
    "\n",
    "    print(\"\\033[92mAll test passed\")\n",
    "\n",
    "compute_cost_test(compute_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b9ef28",
   "metadata": {},
   "source": [
    "### what is memory bottleneck?\n",
    "A memory bottleneck refers to a memory shortage due to insufficient memory, memory leaks, defective programs or when slow memory is used in a fast processor system. A memory bottleneck affects the machine's performance by slowing down the movement of data between the CPU and the RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ece83dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.0001,\n",
    "         num_epochs=1500, minibatch_size=32, print_cost=True):\n",
    "    costs = []\n",
    "    parameters = initialize_parameters()\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    b3 = parameters[\"b3\"]\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "    \n",
    "    # If your program depends on the batches having the same outer dimension, \n",
    "    # you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n",
    "\n",
    "\n",
    "    X_train = X_train.batch(minibatch_size, drop_remainder=True).prefetch(8)\n",
    "    Y_train = Y_train.batch(minibatch_size, drop_remainder=True).prefetch(8)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_cost = 0.\n",
    "        \n",
    "        for (minibatch_X, minibatch_Y) in zip(X_train, Y_train):\n",
    "            with tf.GradientTape() as tape:\n",
    "                Z3 = forward_propagation(minibatch_X, parameters)\n",
    "                minibatch_cost = compute_cost(Z3, minibatch_Y)\n",
    "                \n",
    "            trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
    "            grads = tape.gradient(minibatch_cost, trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "            epoch_cost += minibatch_cost / minibatch_size\n",
    "        \n",
    "        if print_cost == True and epoch % 10 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))            \n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            costs.append(epoch_cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per fives)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    # Save the parameters in a variable\n",
    "    print (\"Parameters have been trained!\")\n",
    "\n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2132e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.649044\n",
      "Cost after epoch 10: 0.604877\n",
      "Cost after epoch 20: 0.582356\n",
      "Cost after epoch 30: 0.564854\n",
      "Cost after epoch 40: 0.549586\n",
      "Cost after epoch 50: 0.536739\n",
      "Cost after epoch 60: 0.526052\n",
      "Cost after epoch 70: 0.516995\n",
      "Cost after epoch 80: 0.509201\n",
      "Cost after epoch 90: 0.502472\n",
      "Cost after epoch 100: 0.496593\n",
      "Cost after epoch 110: 0.491454\n",
      "Cost after epoch 120: 0.486965\n",
      "Cost after epoch 130: 0.483026\n",
      "Cost after epoch 140: 0.479581\n",
      "Cost after epoch 150: 0.476558\n",
      "Cost after epoch 160: 0.473880\n",
      "Cost after epoch 170: 0.471527\n",
      "Cost after epoch 180: 0.469446\n",
      "Cost after epoch 190: 0.467602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': <tf.Variable 'Variable:0' shape=(25, 12288) dtype=float32, numpy=\n",
       " array([[-0.00362652, -0.00460723,  0.01456246, ...,  0.01382768,\n",
       "          0.00927871, -0.00812915],\n",
       "        [-0.00593991, -0.01676408,  0.00527415, ...,  0.00828636,\n",
       "         -0.00292361,  0.00013131],\n",
       "        [ 0.00843046,  0.00052047,  0.01484262, ...,  0.00863219,\n",
       "          0.02275358,  0.00342402],\n",
       "        ...,\n",
       "        [-0.00456412,  0.02391429, -0.01242701, ..., -0.01059515,\n",
       "          0.00634554,  0.00828285],\n",
       "        [-0.02008474, -0.01066575, -0.00202228, ..., -0.00574484,\n",
       "          0.02609658,  0.01006267],\n",
       "        [-0.00645422, -0.00461257,  0.02176875, ..., -0.00292949,\n",
       "         -0.00284526,  0.01450794]], dtype=float32)>,\n",
       " 'b1': <tf.Variable 'Variable:0' shape=(25, 1) dtype=float32, numpy=\n",
       " array([[-0.2571621 ],\n",
       "        [-0.05700606],\n",
       "        [-0.2515691 ],\n",
       "        [ 0.1899629 ],\n",
       "        [ 0.3159076 ],\n",
       "        [ 0.17147051],\n",
       "        [ 0.48490408],\n",
       "        [ 0.0573285 ],\n",
       "        [-0.36292887],\n",
       "        [-0.47468835],\n",
       "        [ 0.07681908],\n",
       "        [-0.1901169 ],\n",
       "        [ 0.27596903],\n",
       "        [-0.15233949],\n",
       "        [-0.06878664],\n",
       "        [ 0.10431217],\n",
       "        [-0.13570707],\n",
       "        [-0.29538125],\n",
       "        [-0.06462948],\n",
       "        [ 0.14813241],\n",
       "        [-0.01178963],\n",
       "        [ 0.370815  ],\n",
       "        [-0.3550502 ],\n",
       "        [ 0.27649432],\n",
       "        [ 0.16789374]], dtype=float32)>,\n",
       " 'W2': <tf.Variable 'Variable:0' shape=(12, 25) dtype=float32, numpy=\n",
       " array([[ 9.85245258e-02, -2.99701661e-01, -2.21550852e-01,\n",
       "         -1.62968799e-01,  4.34597671e-01, -8.59229788e-02,\n",
       "          1.84803709e-01, -1.74684748e-01,  3.07314724e-01,\n",
       "          2.37405956e-01,  3.48422110e-01, -2.21985772e-01,\n",
       "          3.34839702e-01,  1.81786910e-01,  4.10585374e-01,\n",
       "         -3.23110253e-01, -1.17660151e-04,  1.29911348e-01,\n",
       "         -3.19897503e-01, -2.55651653e-01,  9.20869336e-02,\n",
       "         -3.59346449e-01, -3.53686482e-01,  2.78674543e-01,\n",
       "         -3.03188741e-01],\n",
       "        [ 5.17104328e-01,  3.28758508e-01, -1.24879807e-01,\n",
       "          1.06021181e-01,  1.44807667e-01,  2.99549222e-01,\n",
       "         -1.77243277e-01,  2.80439705e-01, -2.26176381e-01,\n",
       "         -3.65642570e-02, -4.07003343e-01,  2.34117374e-01,\n",
       "         -5.91117777e-02, -9.85468104e-02,  4.21966493e-01,\n",
       "          7.80844912e-02,  1.21883415e-01,  3.06916267e-01,\n",
       "         -4.27430570e-02,  1.15457088e-01, -1.95532627e-02,\n",
       "         -1.73253879e-01,  1.67242110e-01, -2.13048048e-02,\n",
       "          3.30154933e-02],\n",
       "        [ 2.79691964e-02, -7.05689788e-02, -1.87578753e-01,\n",
       "          2.06010714e-01, -1.11447714e-01,  5.04252553e-01,\n",
       "         -1.07161235e-02, -2.00097948e-01,  1.31514445e-01,\n",
       "          2.71301776e-01,  8.39579627e-02,  1.90185055e-01,\n",
       "         -8.06510448e-02, -1.55588295e-02, -9.68469307e-02,\n",
       "         -6.72462657e-02,  3.42861682e-01,  4.37387407e-01,\n",
       "         -1.40761763e-01, -5.07340789e-01, -3.60526964e-02,\n",
       "          1.13120042e-02, -2.38646716e-01,  4.55115438e-02,\n",
       "          1.44867778e-01],\n",
       "        [ 2.34047845e-01, -2.97816366e-01, -2.13852182e-01,\n",
       "         -4.86294739e-02,  7.57999569e-02,  6.54308572e-02,\n",
       "         -3.57973963e-01, -1.62241355e-01,  9.37478268e-04,\n",
       "          4.34882790e-02,  2.03745991e-01,  3.86402965e-01,\n",
       "         -2.09142894e-01,  2.23137543e-01, -2.68777072e-01,\n",
       "         -3.42374772e-01, -4.08136249e-02,  6.53310567e-02,\n",
       "          1.53903216e-01, -2.17247471e-01, -3.30866426e-02,\n",
       "         -8.14116448e-02,  9.40301046e-02,  1.70988962e-01,\n",
       "         -3.41132909e-01],\n",
       "        [ 2.78196484e-01, -1.89025313e-01,  4.47253026e-02,\n",
       "         -4.87569392e-01,  7.42218271e-02,  6.67932630e-02,\n",
       "          1.95613906e-01,  1.30047098e-01,  2.98905790e-01,\n",
       "         -1.35658458e-01,  1.00768894e-01, -2.46963009e-01,\n",
       "          9.41933542e-02, -1.55708687e-02,  5.63252084e-02,\n",
       "          6.97574988e-02, -3.21672469e-01,  2.55012929e-01,\n",
       "         -7.53130093e-02, -3.53367716e-01, -4.54132318e-01,\n",
       "         -1.48460180e-01, -2.85412967e-01,  2.53865927e-01,\n",
       "         -2.41741434e-01],\n",
       "        [-3.83072579e-03,  1.35464817e-01,  1.57523289e-01,\n",
       "         -2.83140950e-02, -1.99339166e-01,  3.94355655e-01,\n",
       "         -1.05914086e-01, -2.46494021e-02, -3.24558228e-01,\n",
       "         -1.81385800e-01,  1.43611997e-01,  2.97701418e-01,\n",
       "          7.76655599e-02, -1.04668982e-01, -8.17506015e-03,\n",
       "         -3.46436143e-01,  1.89583376e-01,  5.22622392e-02,\n",
       "         -5.16176283e-01, -3.26399237e-01, -5.37012890e-03,\n",
       "          4.41058306e-03, -2.20316991e-01,  4.42280546e-02,\n",
       "         -7.49507174e-02],\n",
       "        [-4.61692959e-01, -3.94521542e-02, -2.47103587e-01,\n",
       "          2.35082030e-01,  1.42781183e-01,  3.36811781e-01,\n",
       "         -2.87960693e-02,  3.92156392e-02, -6.18620329e-02,\n",
       "          2.21493453e-01, -1.20871559e-01,  1.41174808e-01,\n",
       "         -1.56130373e-01, -3.45389843e-01,  9.55551192e-02,\n",
       "          1.24006994e-01, -3.51878703e-02, -1.72924978e-04,\n",
       "          2.34315231e-01,  4.80685681e-01,  4.79825467e-01,\n",
       "          7.78322518e-02,  8.12656507e-02, -1.61671266e-01,\n",
       "          6.63485825e-02],\n",
       "        [ 6.13305010e-02,  4.74212050e-01, -4.21215817e-02,\n",
       "          1.24165393e-01, -8.37856159e-02, -5.71703650e-02,\n",
       "          3.31544727e-01, -2.68686384e-01,  3.20086062e-01,\n",
       "         -1.24149911e-01,  2.88733114e-02, -3.34953547e-01,\n",
       "         -1.64048538e-01,  9.91591066e-02,  4.55149591e-01,\n",
       "         -2.27882266e-01,  3.85963731e-03, -2.99395174e-01,\n",
       "         -4.91975039e-01, -2.73167312e-01, -3.44941497e-01,\n",
       "          1.62466392e-01,  1.75180770e-02, -3.79353434e-01,\n",
       "          3.09088826e-01],\n",
       "        [-3.56270522e-02,  1.77708417e-01, -3.67821336e-01,\n",
       "         -9.44628045e-02, -1.35983407e-01,  7.58187426e-03,\n",
       "         -4.16761070e-01, -3.76478359e-02,  1.01557203e-01,\n",
       "         -4.32189286e-01,  9.31246951e-02, -4.12760675e-02,\n",
       "          3.96239907e-01, -2.17400014e-01,  2.84484029e-01,\n",
       "          4.54075038e-02, -5.98518476e-02, -1.75546020e-01,\n",
       "          4.08074647e-01,  1.99939892e-01,  4.49243307e-01,\n",
       "         -1.37235060e-01, -2.21130386e-01, -4.10226285e-01,\n",
       "         -3.97041082e-01],\n",
       "        [-4.18756634e-01,  3.10856044e-01,  1.99356936e-02,\n",
       "         -2.13067800e-01, -1.75024778e-01,  8.08627307e-02,\n",
       "         -3.00035864e-01, -3.27183604e-01, -1.42353699e-01,\n",
       "          2.67617553e-01, -4.41793889e-01,  3.87351006e-01,\n",
       "          1.72377229e-01,  4.72774267e-01, -4.75428790e-01,\n",
       "          2.83422500e-01,  4.50352579e-02,  2.35947326e-01,\n",
       "          8.79851058e-02,  4.17416036e-01, -4.10293818e-01,\n",
       "          9.14993172e-04,  1.59136891e-01, -6.01163693e-02,\n",
       "         -6.71415925e-02],\n",
       "        [-3.52235496e-01,  2.29638264e-01,  3.92276108e-01,\n",
       "         -1.23949898e-02, -7.29134008e-02, -1.56591814e-02,\n",
       "         -3.94522667e-01, -6.10281620e-03,  7.47707393e-03,\n",
       "          6.99911937e-02,  2.22927287e-01, -1.29611641e-01,\n",
       "          7.12662563e-02,  2.20410875e-03,  2.60679305e-01,\n",
       "          2.36413069e-02, -4.34899179e-04, -1.19335048e-01,\n",
       "          7.52541274e-02,  5.19424438e-01, -6.94250986e-02,\n",
       "         -2.47553587e-01, -2.86949366e-01,  2.16430306e-01,\n",
       "          1.47091433e-01],\n",
       "        [ 3.78382266e-01, -1.51364565e-01,  1.97811380e-01,\n",
       "          1.00621894e-01, -3.87894735e-02, -1.26218319e-01,\n",
       "         -5.01224361e-02,  2.96834916e-01,  1.76030084e-01,\n",
       "         -9.70712379e-02, -2.32777968e-01, -4.06726360e-01,\n",
       "         -1.44937515e-01, -3.13936383e-01, -5.16579568e-01,\n",
       "         -1.68807209e-01, -1.76858649e-01,  4.04413901e-02,\n",
       "         -8.87333825e-02,  2.19474849e-03,  8.96257758e-02,\n",
       "         -8.57289135e-02, -3.78109992e-01, -1.36431545e-01,\n",
       "          5.29972278e-02]], dtype=float32)>,\n",
       " 'b2': <tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
       " array([[ 0.08481994],\n",
       "        [ 0.31524456],\n",
       "        [ 0.1615311 ],\n",
       "        [ 0.5897149 ],\n",
       "        [ 0.5658821 ],\n",
       "        [ 0.6923719 ],\n",
       "        [ 0.2773988 ],\n",
       "        [-0.08712794],\n",
       "        [-0.3203248 ],\n",
       "        [ 0.6370569 ],\n",
       "        [-0.57969165],\n",
       "        [ 0.00159332]], dtype=float32)>,\n",
       " 'W3': <tf.Variable 'Variable:0' shape=(6, 12) dtype=float32, numpy=\n",
       " array([[-0.06337694, -0.4817153 , -0.5265067 , -0.29172483,  0.15054077,\n",
       "         -0.17386952, -0.4357334 , -0.44331485,  0.21908754, -0.354198  ,\n",
       "         -0.23952387,  0.19586287],\n",
       "        [ 0.14477721,  0.1940571 ,  0.606711  ,  0.02829893,  0.0850416 ,\n",
       "          0.1402691 ,  0.20871837,  0.27542523,  0.27541733,  0.23682708,\n",
       "         -0.22150056,  0.17667645],\n",
       "        [-0.2729683 , -0.23903365,  0.38932067, -0.17959197, -0.14337216,\n",
       "          0.348167  ,  0.33290583,  0.38715145,  0.19353113,  0.53158367,\n",
       "          0.17062448, -0.14059438],\n",
       "        [-0.23375599,  0.27502906,  0.17445432, -0.32333568, -0.36825925,\n",
       "         -0.03576805,  0.34740084,  0.08441455,  0.34903467,  0.28166735,\n",
       "          0.13535109,  0.40962768],\n",
       "        [-0.05638319, -0.3359271 ,  0.24575911,  0.1589555 , -0.6233346 ,\n",
       "          0.4168589 , -0.23380135, -0.4903003 , -0.14218943,  0.23402296,\n",
       "         -0.00369318,  0.38414994],\n",
       "        [ 0.5219068 , -0.392798  ,  0.06559023,  0.40029854, -0.23158588,\n",
       "          0.03577362, -0.15661559,  0.03366266, -0.11398031,  0.13926935,\n",
       "         -0.1708327 , -0.14232273]], dtype=float32)>,\n",
       " 'b3': <tf.Variable 'Variable:0' shape=(6, 1) dtype=float32, numpy=\n",
       " array([[ 0.86905646],\n",
       "        [-0.54621047],\n",
       "        [-0.35556227],\n",
       "        [ 0.13375214],\n",
       "        [ 0.08378051],\n",
       "        [-1.0873723 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_train, new_y_train, new_test, new_y_test, num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3e0a7",
   "metadata": {},
   "source": [
    "In this assignment, you were introducted to tf.GradientTape, which records operations for differentation. \n",
    "\n",
    "* Used tf.Variable to modify your variables\n",
    "* Applied TensorFlow decorators and observed how they sped up your code\n",
    "* Trained a Neural Network on a TensorFlow dataset\n",
    "* Applied batch normalization for a more robust network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54273222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21492b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18790394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a62609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d161433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
